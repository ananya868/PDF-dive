{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d9d7ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56d38140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open \n",
    "with open(\"prompt/summarizer_prompt.yaml\", \"r\") as f:\n",
    "    # load the yaml file\n",
    "    prompt = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25b7e5e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'new': 'hello how are you, can you say hi {var}'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b405d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b00a4931",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_content = \"\"\"\n",
    "Abstract/Summary of Undergraduate Research Project\n",
    "1. Applicant Details:\n",
    "•\n",
    "Name: Ananya Kumar\n",
    "•\n",
    "Email: ananya8154@gmail.com\n",
    "•\n",
    "Undergraduate Institution: Lovely Professional University, Phagwara, India\n",
    "•\n",
    "Undergraduate Degree: Bachelor of Technology in Computer Science and Engineering\n",
    "2. Project Details:\n",
    "•\n",
    "Title of Work: Vision-based Littering Detection and Face Tagging using multi-model Architecture\n",
    "•\n",
    "Link - https://ieeexplore.ieee.org/document/10616763\n",
    "•\n",
    "Type of Work: Academic Research Paper (developed as part of my Final Year Project/Bachelor's Thesis)\n",
    "•\n",
    "Date of Completion/Publication: Published in IEEE Conference/Journal on 9th August, 2024\n",
    "•\n",
    "Supervisor: Jaspreet Kaur, Assistant Professor, Department of Computer Science & Technology, Lovely Professional University\n",
    "3. Fulfilment of University Requirements:\n",
    "•\n",
    "Undergraduate Degree Outside Germany: My undergraduate degree was attained from Lovely Professional University in Phagwara, India.\n",
    "•\n",
    "Evidence of 10 ECTS Credits for a Project: My undergraduate institution, Lovely Professional University, does not formally use the ECTS credit system for its programs.\n",
    "o\n",
    "This research project, \"Vision-based Littering Detection and Face Tagging using multi-model Architecture,\" was completed as the mandatory requirement for the course CSE445: Capstone Project (One Semester Course).\n",
    "o\n",
    "This course was officially allocated 10 credit points within the university's internal credit system.\n",
    "o\n",
    "Based on the expected student workload and academic depth, these 10 local credit points are estimated to be equivalent to approximately 14 ECTS credits.\n",
    "o\n",
    "The successful completion of this project, and thus the course, involved extensive tasks including: literature review, custom dataset creation and annotation, system architecture design, multi-model software implementation and integration, rigorous experimental trials, detailed results analysis, and comprehensive manuscript preparation.\n",
    "o\n",
    "Therefore, this Capstone Project, with its equivalent of approximately 14 ECTS credits, significantly fulfils and exceeds the university's requirement for evidence of a project worth at least 10 ECTS credits.\n",
    "•\n",
    "Involved Independent Study: This research was conducted under the supervision of Assistant Professor Jaspreet Kaur. While the paper lists multiple student authors, this required a significant degree of independent problem solving, literature study, algorithmic design, and technical implementation.\n",
    "o\n",
    "Independently developed the custom dataset for litter detection: This involved the entire pipeline from image collection and meticulous annotation (e.g., using Roboflow) to data augmentation. I then personally managed the training and fine-tuning of the YOLOv8 object detection model to achieve accurate trash identification.\n",
    "o\n",
    "Took the lead role in architecting and integrating the multi-model system: I was primarily responsible for the technical integration of the distinct algorithms—YOLOv8 (trash detection), MediaPipe (pose estimation), and Dlib (face recognition). Crucially, I developed the core computer vision logic that intelligently links human pose with detected objects to infer and identify a littering event.\n",
    "o\n",
    "Applied and adapted core scientific and computer vision methodologies: This included selecting appropriate algorithms, designing the interaction logic between modules, and implementing the methods for data processing and decision-making within the system to ensure it effectively addressed the research problem.\n",
    "•\n",
    "Using Scientific Methods: The project employed a rigorous scientific methodology, including:\n",
    "o\n",
    "A comprehensive literature review of existing litter detection, object detection, pose estimation, and face recognition techniques.\n",
    "o\n",
    "Design and development of a novel multi-model system architecture integrating YOLOv8 for object (trash) detection, MediaPipe for human pose estimation, and Dlib for face recognition.\n",
    "o\n",
    "Creation and curation of a custom dataset for littering actions, involving video recording, image extraction, and manual annotation on Roboflow, including data augmentation.\n",
    "o\n",
    "Systematic experimentation involving 18 trials to evaluate the model's effectiveness in real-world scenarios.\n",
    "o\n",
    "Quantitative analysis of the system's performance using established metrics such as precision (achieved 0.947) and recall (achieved 0.857).\n",
    "o\n",
    "Ablation study considerations for individual components (as discussed in Section V of the paper).\n",
    "o\n",
    "Development of a method to identify the relationship between human joints (hands) and detected objects to infer the act of littering.\n",
    "•\n",
    "Requirement to Present Written Findings: The research culminated in the comprehensive academic research paper titled \"Vision-based Littering Detection and Face Tagging using multi-model Architecture,\" which details the\n",
    "problem statement, proposed methodology, experimental setup, results, and conclusions. This paper serves as the written findings of the project.\n",
    "4. Abstract/Summary of the Research Work:\n",
    "•\n",
    "Introduction/Objective: This research introduced a novel framework to detect illegitimate littering actions using a multi-model computer vision architecture. The primary objective was to address the pervasive issue of littering by leveraging computer vision to identify the act of littering and tag potential litterers, a feature not extensively covered in existing literature.\n",
    "•\n",
    "Methodology: The system utilizes a multi-model architecture integrating:\n",
    "1.\n",
    "YOLOv8: For real-time detection of various trash items, trained on a custom dataset.\n",
    "2.\n",
    "MediaPipe Pose Estimation: To detect human pose landmarks, specifically hand coordinates.\n",
    "3.\n",
    "Dlib Face Recognition: To identify and tag individuals involved in the littering act. The core logic involves establishing a spatial relationship between the detected object (trash) and the person's hand landmarks to infer a littering action.\n",
    "•\n",
    "Key Findings/Results: The system was evaluated through 18 real-world trials, demonstrating high effectiveness. It achieved an overall precision of 0.947 and a recall of 0.857. The experimental analysis confirmed the viability of individual components and the integrated system for detecting littering actions and identifying potential litterers.\n",
    "•\n",
    "Conclusion/Significance & Demonstration of Independent Problem Solving: The research successfully developed and validated an innovative approach for vision-based littering detection and face tagging. This project demonstrated my ability to identify a significant societal problem (environmental pollution due to littering), independently research and conceptualize a complex technological solution by integrating multiple advanced scientific methods and AI models, implement this solution including custom dataset creation, rigorously test its efficacy through systematic experimentation, and articulate the findings in a formal academic research paper. The approach holds promise for creating cleaner and more sustainable communities by providing a tool for monitoring and deterring littering.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "485eaf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open a text file \n",
    "with open(\"prompt/overview_short_summary_prompt.txt\", \"r\") as f:\n",
    "    # read the content of the file\n",
    "    data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "acf7d3e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert summarizer AI. Your task is to create a SHORT, concise, yet informative summary of the provided PDF content. The summary must be highly scannable, visually appealing, and strictly adhere to the specified Markdown format.\n",
      "\n",
      "**Output Format Instructions (Strictly Adhere to Markdown):**\n",
      "\n",
      "The markdown will have these three components: \n",
      "1.  **Document Title:**\n",
      "    *   Start with a Level 1 Markdown heading: `# [Extracted or Inferred Document Title]`.\n",
      "    *   If no clear title is present in the text, create a concise and descriptive one based on the content.\n",
      "\n",
      "2.  **Overall One-Liner Summary:**\n",
      "    *   Immediately following the title heading (on the next line), provide a single, *italic* format, ultra-concise sentence (1-2 sentences maximum) summarizing the entire document's main point, core argument, or purpose.\n",
      "    *   Example: `*This document provides a comprehensive analysis of market trends in the renewable energy sector for Q3 2023, highlighting key growth drivers and potential challenges.*`\n",
      "\n",
      "horizontal line here (---)\n",
      "\n",
      "3.  **Core Highlights (5-12 bullet points):**\n",
      "    *   Follow with a Level 2 Markdown heading: `## Core Highlights`.\n",
      "    *   Under this heading, provide 5-12 bullet points. These bullet points should collectively offer a concise summary of the entire document, capturing its most important sections, main ideas, significant findings, arguments, or logical divisions.\n",
      "    *   If the document has explicit sections or clear paragraph groupings focusing on different sub-topics, ensure these are represented across the bullet points.\n",
      "    *   If the document structure is less obvious, identify the main logical segments or arguments and provide a concise bullet point summary for each.\n",
      "    *   **Formatting within these bullet points (Strictly apply for engagement):**\n",
      "        *   Each bullet point must be brief and to the point.\n",
      "        *   After each bullet point, there should two line spaces '\\n\\n'\n",
      "        *   Emphasize the **most important key terms or phrases** within each bullet point by making them **bold**. Use bolding accurately and judiciously.\n",
      "        *   **You MUST use triple backticks (e.g., ` ```term_or_quote``` `) where appropriate** if specific technical terms, jargon, code snippets, commands, product names, or direct short quotes (1-3 words) need to be highlighted as distinct blocks or literal strings. Actively look for opportunities to use backticks to visually distinguish these elements. Ensure at least a few instances of backticks are present if the content allows.\n",
      "        *   Apply these formatting elements thoughtfully and consistently to make the bullet points visually engaging and easy to scan.\n",
      "\n",
      "**Follow-up Questions:**\n",
      "    *   Generate a list of 5 relevant and thought-provoking questions that a reader might have after engaging with the full content of the PDF.\n",
      "    *   These questions should encourage deeper thinking, exploration of implications, or clarification of points within the document.\n",
      "\n",
      "**General Guidelines:**\n",
      "*   **Brevity and Focus:** This is a *short* summary. The \"Core Highlights\" section should be a distillation of the entire document into its most essential points.\n",
      "*   **Strict Adherence to Format:** The entire output must strictly follow the Markdown structure and formatting elements described above.\n",
      "*   **Clarity and Objectivity:** Use clear, objective, and concise language.\n",
      "*   **Factual Extraction:** Focus on extracting factual information and core arguments.\n",
      "*   **No External Information:** Do not add any information not present in the document.\n",
      "*   **No Conversational Fluff:** Go straight to the summary. Do not include conversational introductions, apologies, or self-references.\n",
      "\n",
      "The output should be primarily two entities: \n",
      "markdown_content (which include the markdown content generated)\n",
      "followup_questions \n",
      "\n",
      "**PDF Content to Summarize:**\n",
      "---\n",
      "\n",
      "Abstract/Summary of Undergraduate Research Project\n",
      "1. Applicant Details:\n",
      "•\n",
      "Name: Ananya Kumar\n",
      "•\n",
      "Email: ananya8154@gmail.com\n",
      "•\n",
      "Undergraduate Institution: Lovely Professional University, Phagwara, India\n",
      "•\n",
      "Undergraduate Degree: Bachelor of Technology in Computer Science and Engineering\n",
      "2. Project Details:\n",
      "•\n",
      "Title of Work: Vision-based Littering Detection and Face Tagging using multi-model Architecture\n",
      "•\n",
      "Link - https://ieeexplore.ieee.org/document/10616763\n",
      "•\n",
      "Type of Work: Academic Research Paper (developed as part of my Final Year Project/Bachelor's Thesis)\n",
      "•\n",
      "Date of Completion/Publication: Published in IEEE Conference/Journal on 9th August, 2024\n",
      "•\n",
      "Supervisor: Jaspreet Kaur, Assistant Professor, Department of Computer Science & Technology, Lovely Professional University\n",
      "3. Fulfilment of University Requirements:\n",
      "•\n",
      "Undergraduate Degree Outside Germany: My undergraduate degree was attained from Lovely Professional University in Phagwara, India.\n",
      "•\n",
      "Evidence of 10 ECTS Credits for a Project: My undergraduate institution, Lovely Professional University, does not formally use the ECTS credit system for its programs.\n",
      "o\n",
      "This research project, \"Vision-based Littering Detection and Face Tagging using multi-model Architecture,\" was completed as the mandatory requirement for the course CSE445: Capstone Project (One Semester Course).\n",
      "o\n",
      "This course was officially allocated 10 credit points within the university's internal credit system.\n",
      "o\n",
      "Based on the expected student workload and academic depth, these 10 local credit points are estimated to be equivalent to approximately 14 ECTS credits.\n",
      "o\n",
      "The successful completion of this project, and thus the course, involved extensive tasks including: literature review, custom dataset creation and annotation, system architecture design, multi-model software implementation and integration, rigorous experimental trials, detailed results analysis, and comprehensive manuscript preparation.\n",
      "o\n",
      "Therefore, this Capstone Project, with its equivalent of approximately 14 ECTS credits, significantly fulfils and exceeds the university's requirement for evidence of a project worth at least 10 ECTS credits.\n",
      "•\n",
      "Involved Independent Study: This research was conducted under the supervision of Assistant Professor Jaspreet Kaur. While the paper lists multiple student authors, this required a significant degree of independent problem solving, literature study, algorithmic design, and technical implementation.\n",
      "o\n",
      "Independently developed the custom dataset for litter detection: This involved the entire pipeline from image collection and meticulous annotation (e.g., using Roboflow) to data augmentation. I then personally managed the training and fine-tuning of the YOLOv8 object detection model to achieve accurate trash identification.\n",
      "o\n",
      "Took the lead role in architecting and integrating the multi-model system: I was primarily responsible for the technical integration of the distinct algorithms—YOLOv8 (trash detection), MediaPipe (pose estimation), and Dlib (face recognition). Crucially, I developed the core computer vision logic that intelligently links human pose with detected objects to infer and identify a littering event.\n",
      "o\n",
      "Applied and adapted core scientific and computer vision methodologies: This included selecting appropriate algorithms, designing the interaction logic between modules, and implementing the methods for data processing and decision-making within the system to ensure it effectively addressed the research problem.\n",
      "•\n",
      "Using Scientific Methods: The project employed a rigorous scientific methodology, including:\n",
      "o\n",
      "A comprehensive literature review of existing litter detection, object detection, pose estimation, and face recognition techniques.\n",
      "o\n",
      "Design and development of a novel multi-model system architecture integrating YOLOv8 for object (trash) detection, MediaPipe for human pose estimation, and Dlib for face recognition.\n",
      "o\n",
      "Creation and curation of a custom dataset for littering actions, involving video recording, image extraction, and manual annotation on Roboflow, including data augmentation.\n",
      "o\n",
      "Systematic experimentation involving 18 trials to evaluate the model's effectiveness in real-world scenarios.\n",
      "o\n",
      "Quantitative analysis of the system's performance using established metrics such as precision (achieved 0.947) and recall (achieved 0.857).\n",
      "o\n",
      "Ablation study considerations for individual components (as discussed in Section V of the paper).\n",
      "o\n",
      "Development of a method to identify the relationship between human joints (hands) and detected objects to infer the act of littering.\n",
      "•\n",
      "Requirement to Present Written Findings: The research culminated in the comprehensive academic research paper titled \"Vision-based Littering Detection and Face Tagging using multi-model Architecture,\" which details the\n",
      "problem statement, proposed methodology, experimental setup, results, and conclusions. This paper serves as the written findings of the project.\n",
      "4. Abstract/Summary of the Research Work:\n",
      "•\n",
      "Introduction/Objective: This research introduced a novel framework to detect illegitimate littering actions using a multi-model computer vision architecture. The primary objective was to address the pervasive issue of littering by leveraging computer vision to identify the act of littering and tag potential litterers, a feature not extensively covered in existing literature.\n",
      "•\n",
      "Methodology: The system utilizes a multi-model architecture integrating:\n",
      "1.\n",
      "YOLOv8: For real-time detection of various trash items, trained on a custom dataset.\n",
      "2.\n",
      "MediaPipe Pose Estimation: To detect human pose landmarks, specifically hand coordinates.\n",
      "3.\n",
      "Dlib Face Recognition: To identify and tag individuals involved in the littering act. The core logic involves establishing a spatial relationship between the detected object (trash) and the person's hand landmarks to infer a littering action.\n",
      "•\n",
      "Key Findings/Results: The system was evaluated through 18 real-world trials, demonstrating high effectiveness. It achieved an overall precision of 0.947 and a recall of 0.857. The experimental analysis confirmed the viability of individual components and the integrated system for detecting littering actions and identifying potential litterers.\n",
      "•\n",
      "Conclusion/Significance & Demonstration of Independent Problem Solving: The research successfully developed and validated an innovative approach for vision-based littering detection and face tagging. This project demonstrated my ability to identify a significant societal problem (environmental pollution due to littering), independently research and conceptualize a complex technological solution by integrating multiple advanced scientific methods and AI models, implement this solution including custom dataset creation, rigorously test its efficacy through systematic experimentation, and articulate the findings in a formal academic research paper. The approach holds promise for creating cleaner and more sustainable communities by providing a tool for monitoring and deterring littering.\n",
      "\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "print(data.format(\n",
    "    num_core_points = \"5-12\", \n",
    "    num_followup_questions = 5, \n",
    "    pdf_text = pdf_content\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d1818c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = \"\"\" \n",
    "- **Custom Dataset**: Independently created and annotated a dataset using `Roboflow`, including image collection, annotation, and data augmentation for training.\n",
    "  \n",
    "- **System Design**: Designed logic linking **human hand landmarks** to detected **trash objects** to identify littering actions accurately.\n",
    "  \n",
    "- **Scientific Methodology**: Conducted a **literature review**, systematic experimentation with **18 trials**, and quantitative analysis to validate the system.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c7e4554f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\n    - **Custom Dataset**: Independently created and annotated a dataset using `Roboflow`, including image collection, annotation, and data augmentation for training.\\n  \\n- **System Design**: Designed logic linking **human hand landmarks** to detected **trash objects** to identify littering actions accurately.\\n  \\n- **Scientific Methodology**: Conducted a **literature review**, systematic experimentation with **18 trials**, and quantitative analysis to validate the system.\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950e9c34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
